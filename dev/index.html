<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · BenchmarkDataNLP.jl</title><meta name="title" content="Home · BenchmarkDataNLP.jl"/><meta property="og:title" content="Home · BenchmarkDataNLP.jl"/><meta property="twitter:title" content="Home · BenchmarkDataNLP.jl"/><meta name="description" content="Documentation for BenchmarkDataNLP.jl."/><meta property="og:description" content="Documentation for BenchmarkDataNLP.jl."/><meta property="twitter:description" content="Documentation for BenchmarkDataNLP.jl."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>BenchmarkDataNLP.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Purpose-and-Approach"><span>Purpose and Approach</span></a></li><li><a class="tocitem" href="#Output-Format-and-File-Structure"><span>Output Format and File Structure</span></a></li><li><a class="tocitem" href="#Functions"><span>Functions</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/mantzaris/BenchmarkDataNLP.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/mantzaris/BenchmarkDataNLP.jl/blob/main/docs/src/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="BenchmarkDataNLP.jl"><a class="docs-heading-anchor" href="#BenchmarkDataNLP.jl">BenchmarkDataNLP.jl</a><a id="BenchmarkDataNLP.jl-1"></a><a class="docs-heading-anchor-permalink" href="#BenchmarkDataNLP.jl" title="Permalink"></a></h1><ul><li><a href="#BenchmarkDataNLP.jl">BenchmarkDataNLP.jl</a></li><li><a href="#Introduction">Introduction</a></li><li class="no-marker"><ul><li><a href="#Purpose-and-Approach">Purpose and Approach</a></li><li><a href="#Output-Format-and-File-Structure">Output Format and File Structure</a></li><li><a href="#Functions">Functions</a></li></ul></li></ul><h1 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h1><p>BenchmarkDataNLP.jl is a Julia package designed to generate synthetic text corpora with adjustable complexity, facilitating the benchmarking and evaluation of Natural Language Processing (NLP) models, including Large Language Models (LLMs). By providing a controlled environment, researchers can systematically assess model performance across varying linguistic structures and complexities.</p><h2 id="Purpose-and-Approach"><a class="docs-heading-anchor" href="#Purpose-and-Approach">Purpose and Approach</a><a id="Purpose-and-Approach-1"></a><a class="docs-heading-anchor-permalink" href="#Purpose-and-Approach" title="Permalink"></a></h2><p>The primary goal of BenchmarkDataNLP.jl is to offer a suite of methods for creating synthetic datasets that mimic various linguistic patterns. These datasets are instrumental in:</p><ul><li>Model Evaluation: Assessing how NLP models handle different levels of language complexity.</li><li>Controlled Testing: Providing datasets with known properties to isolate and test specific model behaviors.</li><li>Resource Efficiency: Generating datasets that allow for efficient training and evaluation within manageable timeframes and computational resources.</li></ul><p>The package employs several methods to generate text, each offering a unique approach to dataset creation:</p><ul><li>Context-Free Grammars (CFGs): Utilizes CFGs to produce sentences based on predefined grammatical rules, allowing for the generation of structured and hierarchical language constructs.</li><li>Resource Description Framework (RDF) Templates: Incorporates RDF templates to structure data, facilitating the generation of text that aligns with specific semantic frameworks. This approach ensures that the generated text adheres to predefined data schemas, enhancing consistency and relevance.</li><li>Templates: Employs predefined templates to guide text generation, ensuring that the output follows specific structural patterns. This method allows for the creation of text with consistent formatting and organization, which is particularly useful for generating repetitive or formulaic content.</li><li>Finite State Machines (FSMs): Implements FSMs to model the generation process as a series of states and transitions, enabling the production of text sequences that follow specific state-dependent rules. This approach is effective in capturing sequential dependencies and ensuring that the generated text adheres to desired patterns.</li></ul><p>Adjustable Complexity</p><p>A key feature of BenchmarkDataNLP.jl is its ability to parameterize the complexity of the generated text. Users can control various parameters, including:</p><ul><li>Vocabulary Size: The number of unique words in the dataset.</li><li>Grammar Rules: The number and complexity of rules used to generate sentences.</li><li>Sentence Length: The maximum length of generated sentences.</li><li>Polysemy: The degree to which words have multiple meanings or roles.</li></ul><p>By adjusting these parameters, users can create datasets ranging from simple, predictable structures to complex, more complex language patterns with elements of randomness or no randomness.</p><h2 id="Output-Format-and-File-Structure"><a class="docs-heading-anchor" href="#Output-Format-and-File-Structure">Output Format and File Structure</a><a id="Output-Format-and-File-Structure-1"></a><a class="docs-heading-anchor-permalink" href="#Output-Format-and-File-Structure" title="Permalink"></a></h2><p>The generated datasets are output in the .jsonl (JSON Lines) format, which is efficient for storing large collections of JSON objects. Each line in the file represents a single data point, facilitating easy parsing and processing. Upon generation, the package produces three separate files corresponding to standard machine learning dataset partitions:</p><ul><li>Training Set: Comprising 80% of the data, used for model training.</li><li>Validation Set: Comprising 10% of the data, used for tuning model parameters.</li><li>Test Set: Comprising 10% of the data, used for evaluating model performance.</li></ul><p>These files are named based on the user-defined base filename and are saved in the specified output directory.</p><h3 id="Usage-Example"><a class="docs-heading-anchor" href="#Usage-Example">Usage Example</a><a id="Usage-Example-1"></a><a class="docs-heading-anchor-permalink" href="#Usage-Example" title="Permalink"></a></h3><p>To generate a dataset with a complexity level of 100, consisting of 100,000 sentences for each of the training, validation, and test sets, you can use the following function call:</p><p>generate<em>corpus</em>CFG(     complexity       = 100,           # Controls grammar, vocab size, etc.     num<em>sentences    = 100</em>000,       # Number of text samples (lines) to generate for each file     enable<em>polysemy  = false,         # Toggle overlap of words among multiple roles     output</em>dir       = &quot;/home/user/Documents&quot;, # Output path for the files     base_filename    = &quot;MyDataset&quot;,   # Base name for output files )</p><p>This function will create three files in the specified directory: MyDataset<em>train.jsonl, MyDataset</em>valid.jsonl, and MyDataset_test.jsonl, containing the generated text samples partitioned accordingly.</p><p>By leveraging BenchmarkDataNLP.jl, researchers and practitioners can efficiently create tailored datasets to rigorously evaluate and benchmark NLP models across a spectrum of linguistic complexities.</p><h2 id="Functions"><a class="docs-heading-anchor" href="#Functions">Functions</a><a id="Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BenchmarkDataNLP.generate_corpus_CFG-Tuple{}" href="#BenchmarkDataNLP.generate_corpus_CFG-Tuple{}"><code>BenchmarkDataNLP.generate_corpus_CFG</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">generate_corpus_CFG(
    ; 
    complexity::Int = 100, 
    num_sentences::Int = 100_000, 
    enable_polysemy::Bool = false, 
    output_dir::AbstractString = &quot;.&quot;, 
    base_filename::AbstractString = &quot;CFG_Corpus&quot;
) -&gt; Nothing</code></pre><p>Generate a synthetic corpus of text using a randomly constructed Context-Free Grammar (CFG).  This function creates a vocabulary (including punctuation), assigns words to various grammar  roles, builds random expansions for each role, and then recursively expands a start role  to produce individual text lines. The corpus is randomly shuffled and split into 80%  training, 10% testing, and 10% validation <code>.jsonl</code> files. It also saves a metadata file  describing the generated grammar.</p><p><strong>Arguments</strong></p><ul><li><p><code>complexity::Int</code> (default = 100): Controls the overall size and complexity of the grammar  and vocabulary. Higher values lead to more roles, more words, and larger expansions  (potentially producing lengthier or more varied sentences). </p><ul><li><strong>Range</strong>: 1 ≤ <code>complexity</code> ≤ 1000.</li><li><strong>Behavior</strong>: <ul><li>At lower values (≈1–10), the grammar is quite small.</li><li>At or beyond 100, expansions can become extensive and less “natural.”</li></ul></li></ul></li><li><p><code>num_sentences::Int</code> (default = 100_000): Total number of text lines (sentences) to generate.</p></li><li><p><code>enable_polysemy::Bool</code> (default = <code>false</code>): If <code>true</code>, words may appear in multiple roles,  introducing lexical ambiguity. If <code>false</code>, each word is assigned to exactly one role.</p></li><li><p><code>output_dir::AbstractString</code> (default = <code>&quot;.&quot;</code>): Directory path to which all output files  (the corpus <code>.jsonl</code> files and metadata <code>.json</code>) are written.</p></li><li><p><code>base_filename::AbstractString</code> (default = <code>&quot;CFG_Corpus&quot;</code>): Base name for output files.  The function writes:</p><ul><li><code>&quot;&lt;base_filename&gt;_metadata.json&quot;</code>: A JSON file describing the generated grammar, roles, etc.</li><li><code>&quot;&lt;base_filename&gt;_training.jsonl&quot;</code>, <code>&quot;&lt;base_filename&gt;_testing.jsonl&quot;</code>, and  <code>&quot;&lt;base_filename&gt;_validation.jsonl&quot;</code>: The text corpus in JSON Lines format.</li></ul></li></ul><p><strong>Description</strong></p><ol><li><p><strong>Vocabulary &amp; Punctuation</strong>   A base alphabet is sampled given the <code>complexity</code>. Then, punctuation tokens are added.  Words are formed by combining characters from the alphabet (the size of the vocabulary  also scales with <code>complexity</code>).</p></li><li><p><strong>Role Creation</strong>   A set of grammar roles (e.g., <code>Role1</code>, <code>Role2</code>, ...) is generated. The number of roles  grows with <code>complexity</code>. </p></li><li><p><strong>Role Assignment &amp; Polysemy</strong>  </p><ul><li>If <code>enable_polysemy=false</code>, each word is placed into exactly one role’s vocabulary.  </li><li>If <code>enable_polysemy=true</code>, words may appear in multiple roles (e.g., “bat” might be  assigned to both <code>Noun</code> and <code>Verb</code> roles).</li></ul></li><li><p><strong>Grammar Construction</strong>  </p><ul><li>For each role, a number of random expansions is created (scaling with <code>complexity</code>).</li><li>An expansion is a sequence of items, each of which may be another role (non-terminal)  or a terminal word. </li><li>Recursion depth is limited (<code>sentence_recursion_max_depth</code>) to prevent infinite loops  if the expansions reference one another excessively.</li></ul></li><li><p><strong>Sentence Generation</strong>  </p><ul><li>Each of the <code>num_sentences</code> lines is produced by randomly choosing a start role, then  recursively expanding it until only terminal words remain or the maximum recursion depth  is reached. </li><li>The resulting tokens are joined into a single line of text.</li></ul></li><li><p><strong>Output</strong>  </p><ul><li>The generated lines are shuffled and split into train (80%), test (10%), and validation  (10%) sets. </li><li>Three <code>.jsonl</code> files are written: <code>&quot;[base_filename]_training.jsonl&quot;</code>,  <code>&quot;[base_filename]_testing.jsonl&quot;</code>, and <code>&quot;[base_filename]_validation.jsonl&quot;</code>. </li><li>A metadata file, <code>&quot;[base_filename]_metadata.json&quot;</code>, captures the grammar, roles, and  vocabulary used.</li></ul></li></ol><p><strong>Returns</strong></p><p>Nothing. The corpus (train/test/validation) and a metadata file describing the grammar are  saved to disk as JSON files.</p><p><strong>Example</strong></p><p>```julia generate<em>corpus</em>CFG(     complexity      = 100,      num<em>sentences   = 100</em>000,      enable<em>polysemy = true,      output</em>dir      = &quot;/path/to/output&quot;,      base_filename   = &quot;MyCFGCorpus&quot; )</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/BenchmarkDataNLP.jl/blob/b7e05c23c9c7d4e7e7595342683af3aeffcc1ce4/src/cfg_data.jl#L288-L381">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BenchmarkDataNLP.generate_fsm_corpus-Tuple{Int64, Int64}" href="#BenchmarkDataNLP.generate_fsm_corpus-Tuple{Int64, Int64}"><code>BenchmarkDataNLP.generate_fsm_corpus</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">generate_fsm_corpus(
    complexity::Int, 
    num_lines::Int;
    output_dir::String=&quot;.&quot;,
    base_name::String=&quot;MyFSM&quot;,
    use_context::Bool=false,
    random_adjacency::Bool=false,
    max_length::Int=10
) -&gt; Nothing</code></pre><p>Generates a synthetic text corpus by constructing a Finite State Machine (FSM) adjacency structure and &quot;walking&quot; it to produce lines of text. The resulting lines are automatically split into training, testing, and validation sets (80%, 10%, 10%) and saved as JSON lines (<code>.jsonl</code> files).</p><p><strong>Arguments</strong></p><ul><li><code>complexity::Int</code>: Governs the overall size of the vocabulary and the probability of generating terminal (ending) transitions. Higher complexity results in:<ul><li>A larger vocabulary.</li><li>A lower proportion of transitions that lead immediately to a terminal symbol.</li></ul></li><li><code>num_lines::Int</code>: Number of total lines (FSM walks) to generate in the corpus.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>output_dir::String</code>: Directory where the JSONL output files are written (default: <code>&quot;.&quot;</code>).</li><li><code>base_name::String</code>: Base filename for the output files. The function creates three JSONL files named <code>&quot;&lt;base_name&gt;_train.jsonl&quot;</code>, <code>&quot;&lt;base_name&gt;_test.jsonl&quot;</code>, and <code>&quot;&lt;base_name&gt;_val.jsonl&quot;</code>.</li><li><code>use_context::Bool</code>: If <code>true</code>, the vocabulary is split into “context words” and  “normal words,” and context words may appear in expansions more frequently to simulate shared or thematic context. If <code>false</code>, all words are treated uniformly.</li><li><code>random_adjacency::Bool</code>: Controls whether the FSM adjacency (i.e., expansions from each word) is created randomly or deterministically:<ul><li><strong><code>true</code></strong>: Each word randomly links to 1–3 possible expansions, some of which might be terminal. </li><li><strong><code>false</code></strong>: Each word deterministically expands (e.g., in sorted order), thus producing consistent, repeatable chains.</li></ul></li><li><code>max_length::Int</code>: The maximum number of expansions (steps) for each walk (default: <code>10</code>). The walk ends if a terminal is reached or <code>max_length</code> expansions are exceeded.</li></ul><p><strong>Description</strong></p><ol><li><p><strong>Vocabulary Construction</strong>:</p><ul><li>A base alphabet is generated according to the <code>complexity</code>.</li><li>A vocabulary is created from this alphabet, again sized according to <code>complexity</code>.</li><li>If <code>use_context=true</code>, part of this vocabulary is designated as “context words,” while the remaining words serve as “normal words.”</li></ul></li><li><p><strong>FSM Adjacency Building</strong>:</p><ul><li>If <code>random_adjacency=true</code>, each word’s expansions are chosen randomly. A certain fraction of these expansions lead to a terminal symbol (the fraction decreases as  <code>complexity</code> increases).</li><li>Otherwise (for <code>random_adjacency=false</code>), expansions follow a deterministic pattern (e.g., next words in sorted order).</li></ul></li><li><p><strong>Line Generation</strong>:</p><ul><li>For each of the <code>num_lines</code>, a starting word is randomly selected.</li><li>The function performs a round-robin deterministic walk from that starting word up  to <code>max_length</code> expansions or until a terminal expansion is reached. The sequence of tokens visited during this walk is concatenated into a single line of text.</li></ul></li><li><p><strong>Output</strong>:</p><ul><li>All generated lines are randomly shuffled and then split into three sets:<ul><li><strong>Training</strong>: 80%</li><li><strong>Testing</strong>: 10%</li><li><strong>Validation</strong>: 10%</li></ul></li><li>These lines are written in <code>.jsonl</code> format as <code>&lt;base_name&gt;_train.jsonl</code>,  <code>&lt;base_name&gt;_test.jsonl</code>, and <code>&lt;base_name&gt;_val.jsonl</code>.</li></ul></li></ol><p><strong>Returns</strong></p><p>Nothing. The generated text corpus is written to disk in JSONL format.</p><p><strong>Example</strong></p><p>```julia generate<em>fsm</em>corpus(     50,                # complexity -&gt; larger vocabulary, fewer terminal expansions     100;               # produce 100 lines     output<em>dir=&quot;.&quot;,      base</em>name=&quot;MyFSM&quot;,     use<em>context=true,      random</em>adjacency=true,     max_length=12 )</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/BenchmarkDataNLP.jl/blob/b7e05c23c9c7d4e7e7595342683af3aeffcc1ce4/src/fsm_data.jl#L280-L366">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BenchmarkDataNLP.generate_rdf_corpus-Tuple{Int64, Int64}" href="#BenchmarkDataNLP.generate_rdf_corpus-Tuple{Int64, Int64}"><code>BenchmarkDataNLP.generate_rdf_corpus</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">generate_rdf_corpus(
    complexity::Int,
    num_paragraphs::Int;
    output_dir::String=&quot;.&quot;,
    base_name::String=&quot;MyRDF&quot;,
    filler_ratio::Float64=0.0,
    max_filler::Int=0,
    use_context::Bool=false
) -&gt; Nothing</code></pre><p>Generate a synthetic RDF-based text corpus and automatically split it into  training, testing, and validation sets. The corpus is saved as <code>.jsonl</code> files.</p><p><strong>Arguments</strong></p><ul><li><code>complexity::Int</code>: Controls the scale of the generated vocabulary and triple store. Higher complexity leads </li></ul><p>to a larger vocabulary, more subjects/predicates/objects, and potentially a higher number of triples.</p><ul><li><code>num_paragraphs::Int</code>: The total number of lines (or “paragraphs” if <code>use_context=true</code>) to </li></ul><p>produce in the final corpus.</p><ul><li><code>output_dir::String</code>: Directory where output files will be saved (<code>&quot;.&quot;</code> by default).</li><li><code>base_name::String</code>: Base name for the output files. The function will produce three files named </li></ul><p><code>&lt;base_name&gt;_train.jsonl</code>, <code>&lt;base_name&gt;_test.jsonl</code>, and <code>&lt;base_name&gt;_val.jsonl</code>.</p><ul><li><code>filler_ratio::Float64</code>: Fraction of the vocabulary leftover (after allocating subjects, predicates, </li></ul><p>and objects) that is used for filler tokens. For example, a value of <code>0.3</code> means 30% of the leftover words      become filler tokens. A higher ratio produces more distinct filler words you can insert in generated sentences.      If this is <code>0.0</code>, no extra tokens are dedicated to filler.</p><ul><li><code>max_filler::Int</code>: The maximum number of filler tokens inserted around each subject, </li></ul><p>predicate, or object in a generated sentence. For example, if <code>max_filler=2</code>, then up to  two randomly chosen filler tokens might appear before the subject, between subject and  predicate, or between predicate and object.</p><ul><li><code>use_context::Bool</code>: If true, generates multi-sentence paragraphs reusing previously </li></ul><p>mentioned entities (subject/object) within each paragraph, introducing some “context.”  Otherwise, each line is just a single triple-based sentence with no continuity.</p><p><strong>Description</strong></p><ol><li><strong>Vocabulary &amp; Triple Store</strong>: Based on <code>complexity</code>, the function creates a master vocabulary </li></ol><p>and partitions it into subjects, predicates, objects, and (optionally) filler. A random subset  of (subject, predicate, object) combinations is then chosen to form a finite triple store.</p><ol><li><strong>Text Generation</strong>:</li></ol><ul><li>If <code>use_context=false</code>, each line is a single sentence referencing a randomly picked triple, </li></ul><p>optionally inserting up to <code>max_filler</code> filler tokens around the subject/predicate/object.</p><ul><li>If <code>use_context=true</code>, the function produces multi-sentence paragraphs, where each paragraph </li></ul><p>attempts to reuse entities mentioned in prior sentences for added context.</p><ol><li><strong>Output</strong>:</li></ol><ul><li>The resulting lines or paragraphs are shuffled and split into training (80%), testing (10%), </li></ul><p>and validation (10%) sets.</p><ul><li>Saved as JSON lines in files named <code>&lt;base_name&gt;_train.jsonl</code>, <code>&lt;base_name&gt;_test.jsonl</code>, </li></ul><p>and <code>&lt;base_name&gt;_val.jsonl</code> within <code>output_dir</code>.</p><p><strong>Returns</strong></p><p>Nothing. The synthetic corpus is written to disk in JSONL format.</p><p><strong>Example</strong></p><p>```julia generate<em>rdf</em>corpus(     50,     1<em>000;     output</em>dir = &quot;.&quot;,     base<em>name = &quot;MyRDF&quot;,     filler</em>ratio = 0.2,     max<em>filler = 2,     use</em>context = true )</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/BenchmarkDataNLP.jl/blob/b7e05c23c9c7d4e7e7595342683af3aeffcc1ce4/src/rdf_data.jl#L244-L311">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BenchmarkDataNLP.generate_tps_corpus-Tuple{Int64, Int64}" href="#BenchmarkDataNLP.generate_tps_corpus-Tuple{Int64, Int64}"><code>BenchmarkDataNLP.generate_tps_corpus</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">generate_tps_corpus(
    complexity::Int,
    num_lines::Int;
    output_dir::String = &quot;.&quot;,
    base_name::String = &quot;MyTPS&quot;,
    n_templates::Int = 10,
    max_placeholders_in_template::Int = 4,
    deterministic::Bool = false
) -&gt; Nothing</code></pre><p>Generates a synthetic text corpus by filling randomly constructed templates with vocabulary  tokens. The corpus is split into training, testing, and validation sets (80/10/10) and saved  as <code>.jsonl</code> files.</p><p><strong>Arguments</strong></p><ul><li><code>complexity::Int</code>: Governs the size of the vocabulary and the number of available “bridging words.” Higher values increase the overall variety of tokens.</li><li><code>num_lines::Int</code>: Total number of lines (sentences) to generate. These lines are then split  into train (80%), test (10%), and validation (10%) sets.</li><li><code>output_dir::String</code>: Directory path to which the <code>.jsonl</code> files are written (default: <code>&quot;.&quot;</code>).</li><li><code>base_name::String</code>: Base prefix for output files, e.g., <code>&lt;base_name&gt;_train.jsonl</code>,  <code>&lt;base_name&gt;_test.jsonl</code>, and <code>&lt;base_name&gt;_val.jsonl</code> (default: <code>&quot;MyTPS&quot;</code>).</li><li><code>n_templates::Int</code>: Number of randomly generated templates to build (default: <code>10</code>).  Each template specifies a textual skeleton with placeholder slots.</li><li><code>max_placeholders_in_template::Int</code>: Maximum number of placeholder tokens each template  can contain (default: <code>4</code>). These placeholders are drawn from a set of roles (e.g., <code>SUBJECT</code>,  <code>VERB</code>, <code>ADJECTIVE</code>, <code>OBJECT</code>).</li><li><code>deterministic::Bool</code>: If <code>true</code>, placeholders in each template are filled using a  systematic (round-robin) approach. If <code>false</code>, placeholders are chosen randomly from  the available dictionary.</li></ul><p><strong>Description</strong></p><ol><li><p><strong>Vocabulary &amp; Bridging Words</strong>  </p><ul><li>A base vocabulary is built according to <code>complexity</code>. </li><li>A subset of the vocabulary is designated as “bridging words,” which act as connecting tokens  (e.g., <code>&quot;the&quot;</code>, <code>&quot;some&quot;</code>) for the templates.</li><li>The remainder of the vocabulary is partitioned into roles for placeholders  (e.g., <code>:SUBJECT</code>, <code>:VERB</code>, <code>:ADJECTIVE</code>, <code>:OBJECT</code>).</li></ul></li><li><p><strong>Template Construction</strong>  </p><ul><li><code>n_templates</code> are generated, each containing up to <code>max_placeholders_in_template</code> placeholders. </li><li>Between placeholders, random bridging words (or other connectors) are inserted to form a  base template string (e.g., <code>&quot;the {SUBJECT} a {VERB} some {OBJECT}.&quot;</code>).</li></ul></li><li><p><strong>Filling Templates</strong>  </p><ul><li>For each of the <code>num_lines</code> text samples, one template is selected (either in a round-robin  fashion if <code>deterministic=true</code>, or randomly otherwise).</li><li>The placeholders in that template are then filled with actual words from the assigned  placeholder dictionaries. </li><li>A round-robin strategy ensures systematic coverage of each placeholder’s vocabulary, while  random selection injects more variation.</li></ul></li><li><p><strong>Output Splitting &amp; JSONL Writing</strong>  </p><ul><li>All generated lines are shuffled, then split into 80% training, 10% testing, and 10% validation sets.</li><li>Three <code>.jsonl</code> files are created with filenames based on <code>base_name</code>:  <code>&quot;&lt;base_name&gt;_train.jsonl&quot;</code>, <code>&quot;&lt;base_name&gt;_test.jsonl&quot;</code>, and <code>&quot;&lt;base_name&gt;_val.jsonl&quot;</code>.</li><li>Each line in these files is a single JSON object containing the text (e.g., <code>{&quot;text&quot;: &quot;the cat ate some fish.&quot;}</code>).</li></ul></li></ol><p><strong>Returns</strong></p><p>Nothing. The final corpus is written to disk in JSON Lines format.</p><p><strong>Example</strong></p><p>```julia generate<em>tps</em>corpus(     50,                          # complexity     100;                         # num<em>lines     output</em>dir = &quot;./my<em>outputs&quot;, # directory for output JSONL files     base</em>name = &quot;TemplatedTest&quot;, # base prefix for output filenames     n<em>templates = 5,             # how many random templates to generate     max</em>placeholders<em>in</em>template = 4,  # up to 4 placeholders per template     deterministic = false        # if true, fill placeholders round-robin instead of randomly )</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/BenchmarkDataNLP.jl/blob/b7e05c23c9c7d4e7e7595342683af3aeffcc1ce4/src/tps_data.jl#L203-L281">source</a></section></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Monday 10 February 2025 16:28">Monday 10 February 2025</span>. Using Julia version 1.10.8.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
